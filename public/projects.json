[
    {
      "title": "QUALCOMM - AI Emotion Recognition Through Audio & Video",
      "subtitle": "Using computer vision and audio analysis to identify emotions in video",
      "description": "At KAIST, I was invited by Qualcomm to compete in an AI challenge focused on emotion detection from user-recorded videos. Most teams had access to multimillion-dollar compute clusters; we had my MSI gaming laptop. Early on, I realized facial expressions introduced too much variance for reliable inference across populations. Instead, I pivoted to audio. By generating spectrograms from speech segments and analyzing them with computer vision, I found patterns in emotional cadence that generalized better. The approach was fast, lightweight, and surprisingly effective—enough to outperform teams with vastly more resources. Ironically, not speaking Korean at the time probably helped. I couldn’t anchor to linguistic content, so I trusted the signals.", 
      "image": "/images/project1.jpg",
      "date": "Dec 2019",
      "collaborators": ["Daehyeon Nam", "Mina Kim"],
      "sponsors": "Qualcomm, Inc",
      "media": [
        {
          "type": "image",
          "url": "/images/project1-detail1.png",
          "description": "An example spectogram generated after performing normalization functions of the audio data when visualized into image form"
        },
        {
          "type": "image",
          "url": "/images/project1-detail2.png",
          "description": "Example webcam video frame sampled from the video data set"
        }
      ]
    },
    {
      "title": "Crypto Free Lunch Program - A Digital Ledger for Corruption-Free Meal Distribution in Indonesia",
      "subtitle": "Leveraging blockchain to ensure transparency in Indonesia’s proposed Free Lunch Program",
      "description": "When Indonesia announced its national free lunch program, I saw the core failure point immediately: transparency. The real problem isn’t logistics—it’s trust. I toyed around with a prototype of a blockchain-based tracking system for government-funded meals. Each meal is tokenized, verified using proof-of-humanity-style ID (inspired by Worldcoin), and tracked from distribution to consumption. Providers are only reimbursed after confirmed delivery, and all budgets are auditable on-chain. The entire stack is built to eliminate middleman leakage and enforce public accountability without relying on third-party trust. It’s a digital control layer for welfare logistics, designed for real-world edge cases like Indonesia’s. (This project never came to light, but open to share code for anyone interested)",
      "image": "/images/project2.png",
      "date": "Jan 2025",
      "collaborators": ["Jay Lee"],
      "sponsors": "A.K.",
      "media": [
        {
          "type": "image",
          "url": "/images/project2-detail1.png",
          "description": "Initial rollout of student lunch program (not original image)"
        },
        {
          "type": "image",
          "url": "/images/project2-detail2.png",
          "description": "Students can use these simple PoS kiosks to confirm their meal tickets by scanning their face or card (similar to worldcoin's ORB) (not original image)"
        }
      ]
    },
    {
      "title": "PROJECT VCR - SDKs for Low-Compute VR Devices (2019)",
      "subtitle": "Innovating VR streaming and interaction for mobile-first devices",
      "description": "In 2019, most consumer VR still relied on dedicated hardware: PC GPUs, external sensors, and proprietary controllers. At KAIST, we explored how the shift toward Wi-Fi 6 and edge computing could reduce this dependency. The goal was to make high-quality VR more accessible by streaming environments from local servers and enabling interaction through lightweight, on-device tracking. Working with early NVIDIA cloud rendering tools, we built a system that offloaded scene rendering to edge nodes while using onboard vision models for controller-free hand tracking. The prototype ran on mobile chipsets and required no external hardware. While latency remained a challenge, the pipeline demonstrated that near-PC VR experiences could run on low-power devices—months before similar capabilities were announced by Meta.",
      "image": "/images/project3.png",
      "date": "Aug 2019",
      "collaborators": ["Daehyeon Nam"],
      "sponsors": "Han Sangmin",
      "media": [
        {
          "type": "image",
          "url": "/images/project3-detail1.png",
          "description": "Hand-recognition controller pipeline overview"
        },
        {
          "type": "image",
          "url": "/images/project3-detail2.png",
          "description": "After only 1 month of our demo, Facebook released their own version of the low-compute hand-tracking."
        }
      ]
    },
    {
      "title": "Komodo Analytica - AI-Driven Personal Branding Automation",
      "subtitle": "A recursive AI feedback loop for optimizing social media growth",
      "description": "Komodo Analytica is an AI-native feedback loop for automated brand growth. It models audiences based on psychographics and region, generates trend-aware short-form content, and refines strategy using real-time engagement data. The system continuously iterates across platforms, minimizing the gap between insight and execution. It's been used by political campaigns and public figures to scale messaging without needing large media teams. Unlike most 'personal branding tools,' it doesn’t just schedule—it learns, adapts, and improves autonomously. It treats content like code: versioned, tested, and optimized for performance. (K.A is now continued under a different brand and group of engineers)",
      "image": "/images/project4.png",
      "date": "Aug 2024",
      "collaborators": ["Jay Jin"],
      "sponsors": "Sinar Mas Group",
      "media": [
        {
          "type": "image",
          "url": "/images/project4-detail1.png",
          "description": "Komodo Analytica pipeline overview"
        },
        {
          "type": "image",
          "url": "/images/project4-detail2.png",
          "description": "Komodo DB - the Komodo Analytica dashboard for clients to easily manage analytics and choose which content to auto-generate for the next week"
        },
        {
          "type": "image",
          "url": "/images/project4-detail3.png",
          "description": " Clients include Indonesia's Minister of Energy & Minerals' son: https://www.youtube.com/shorts/D4gP-xphn3Y"
        }
      ]
    },
    {
      "title": "RAS - AI-Powered Assisted Living for Alzheimer’s Patients",
      "subtitle": "An emergency response and behavioral monitoring system for smart homes",
      "description": "RAS is a home-based AI system designed to monitor behavioral drift in Alzheimer’s patients. Built on a LiDAR-enabled SLAM engine for dynamic spatial mapping, it tracks patient routines and flags anomalies—like missed medication or unusual movement. The system also includes an audio sentiment analysis layer that assesses vocal urgency, triaging emotional signals to trigger emergency response protocols. The goal was not to over-automate, but to build context-aware, lightweight robotics that can act quickly when things go wrong. RAS blends situational awareness with human-first design, extending safety without compromising autonomy.",
      "image": "/images/project5.png",
      "date": "May 2019",
      "collaborators": ["Glen Duncan"],
      "sponsors": "NIS, NIH",
      "media": [
        {
          "type": "image",
          "url": "/images/project5-detail1.png",
          "description": "Alzheimer's patients who are disabled can trigger emergency response by emotion analysis (not original image)"
        },
        {
          "type": "image",
          "url": "/images/project5-detail2.png",
          "description": "SLAM mapping system for real-time spatial awareness (testing around our lab)"
        },
        {
          "type": "image",
          "url": "/images/project5-detail3.png",
          "description": "V1 bot used turtlebot3 base for movement (V1 bot)"
        }
      ]
    },
    {
      "title": "VRET - AI-Powered Virtual Reality Exposure Therapy",
      "subtitle": "Telehealth solutions for veterans suffering from combat PTSD",
      "description": "Exposure therapy is one of the most effective treatments for PTSD—but for many veterans, accessing it is logistically or emotionally difficult. I built a virtual reality-based therapy platform that simulates adaptive combat triggers and adjusts in real-time based on biofeedback signals like heart rate and stress levels. Patients can connect remotely with therapists, and the platform adjusts exposure intensity as needed, enabling personalized desensitization at scale. Our pilot studies showed reduced physiological fight-or-flight responses over repeated sessions, validating VR as a viable path to democratizing trauma care.",
      "image": "/images/project6.png",
      "date": "April 2019",
      "collaborators": ["Manh Nguyen"],
      "sponsors": "US Veterans Affairs (Cincinnati), MUCAT & Game Lab",
      "media": [
        {
          "type": "image",
          "url": "/images/project6-detail1.png",
          "description": "To stimulate a less extreme fear & trauma response, we simulated a horror experience where we tracked user's heart rate and stress levels in the virtual environement and tried to use VRET to decrease their body's response (not original image)"
        },
        {
          "type": "image",
          "url": "/images/project6-detail2.png",
          "description": "We monitored user's heart rate and stress levels in the virtual environement and tried to use VRET to decrease their body's response (not original image)"
        }
      ]
    },
    {
      "title": "Fanesthesia - Pre-operative Stress Reduction for Adolescent Patients",
      "subtitle": "Mobile app for pre-operative stress reduction for adolescent patients",
      "description": "Fanesthesia is a pre-operative cognitive prep tool designed for adolescent patients undergoing surgery. Traditional hospital protocols do little to address pre-op anxiety, which can increase risk factors and recovery time. Fanesthesia delivers structured mindfulness and cognitive-behavioral exercises in a game-like mobile experience, tailored to reduce cortisol levels and improve surgical readiness. We worked with anesthesiologists to track patient engagement and recovery outcomes. The app was designed to be medically grounded, modular, and usable in both clinical and outpatient settings. It's a lightweight intervention with measurable impact—especially in pediatric contexts.",
      "image": "/images/project7.png",
      "date": "Feb 2018",
      "collaborators": ["Michael Stahr, Sean P. Antosh, MD"],
      "sponsors": "Dayton Children's Hospital",
      "media": [
        {
          "type": "image",
          "url": "/images/project7-detail1.png",
          "description": "Anesthesiologists can easily monitor their patients' progress (not original image)"
        },
        {
          "type": "image",
          "url": "/images/project7-detail2.png",
          "description": "Children are prompted through interactive games to complete their mindfulness exercises (not original image)"
        }
      ]
    }
  ]
  